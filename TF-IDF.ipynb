{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF demo with Python and Pandas\n",
    "# using US Presidential Inaugural speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# February 28, 2017\n",
    "# on the occasion of a collaborative exploration of a common dataset\n",
    "# proposed by the organizers of the Digital Approaches Reading Group\n",
    "# at Washington University in St. Louis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(txt):   # simplified tokenization for demo\n",
    "    return [t for t in re.split(\"\\W+\", txt.lower()) if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frameforpath(filepath):\n",
    "    \"\"\"Given a path to an inaugural file, speech tokenize it, count the tokens, \n",
    "    and create a dataframe where each row consists of filename, token, and count\"\"\"\n",
    "    with open(filepath) as filehandle:\n",
    "        txt = filehandle.read()\n",
    "        tokens = tokenize(txt)\n",
    "        filename = os.path.split(filepath)[-1].replace(\".txt\", \"\")\n",
    "        tokencounts = Counter(tokens)\n",
    "        # Counter gives us a dictionary of tokens and counts;\n",
    "        # next we splice the filename into each row and make a dataframe\n",
    "        datalist = [(filename, token, count) \n",
    "                    for (token, count) in tokencounts.items()]\n",
    "        tmp = pd.DataFrame(datalist)\n",
    "        tmp.columns = ['doc','word','count']        \n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a single dataframe with all the tokens.\n",
    "# Each inaugural's dataframe has the same structure,\n",
    "# and so they can in turn each be appended to \n",
    "# make one frame.\n",
    "filepaths = sorted(glob.glob(\"inauguralspeeches/*.txt\"))\n",
    "df = pd.DataFrame()\n",
    "for filepath in filepaths:\n",
    "    df = df.append(frameforpath(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the full frame: 44681 rows, 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_washington_1789</td>\n",
       "      <td>more</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_washington_1789</td>\n",
       "      <td>should</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_washington_1789</td>\n",
       "      <td>inapplicable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_washington_1789</td>\n",
       "      <td>nor</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_washington_1789</td>\n",
       "      <td>than</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  doc          word  count\n",
       "0  01_washington_1789          more      8\n",
       "1  01_washington_1789        should      1\n",
       "2  01_washington_1789  inapplicable      1\n",
       "3  01_washington_1789           nor      2\n",
       "4  01_washington_1789          than      6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check it out:\n",
    "print(\"The dimensions of the full frame: {0} rows, {1} columns\".format(*df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's turn this into a document-word matrix of word counts, \n",
    "# filling in 0 for any empty cells\n",
    "\n",
    "word_doc = df.pivot_table(index=\"word\", columns=\"doc\", values=\"count\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>doc</th>\n",
       "      <th>01_washington_1789</th>\n",
       "      <th>02_washington_1793</th>\n",
       "      <th>03_adams_john_1797</th>\n",
       "      <th>04_jefferson_1801</th>\n",
       "      <th>05_jefferson_1805</th>\n",
       "      <th>06_madison_1809</th>\n",
       "      <th>07_madison_1813</th>\n",
       "      <th>08_monroe_1817</th>\n",
       "      <th>09_monroe_1821</th>\n",
       "      <th>10_adams_john_quincy_1825</th>\n",
       "      <th>...</th>\n",
       "      <th>49_reagan_1981</th>\n",
       "      <th>50_reagan_1985</th>\n",
       "      <th>51_bush_george_h_w_1989</th>\n",
       "      <th>52_clinton_1993</th>\n",
       "      <th>53_clinton_1997</th>\n",
       "      <th>54_bush_george_w_2001</th>\n",
       "      <th>55_bush_george_w_2005</th>\n",
       "      <th>56_obama_2009</th>\n",
       "      <th>57_obama_2013</th>\n",
       "      <th>58_trump_2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>116.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honor</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "doc      01_washington_1789  02_washington_1793  03_adams_john_1797  \\\n",
       "word                                                                  \n",
       "the                   116.0                13.0               163.0   \n",
       "america                 0.0                 1.0                 5.0   \n",
       "great                   3.0                 0.0                 5.0   \n",
       "honor                   0.0                 1.0                 7.0   \n",
       "\n",
       "doc      04_jefferson_1801  05_jefferson_1805  06_madison_1809  \\\n",
       "word                                                             \n",
       "the                  130.0              143.0            104.0   \n",
       "america                0.0                0.0              0.0   \n",
       "great                  1.0                1.0              0.0   \n",
       "honor                  2.0                0.0              2.0   \n",
       "\n",
       "doc      07_madison_1813  08_monroe_1817  09_monroe_1821  \\\n",
       "word                                                       \n",
       "the                100.0           275.0           360.0   \n",
       "america              0.0             0.0             2.0   \n",
       "great                0.0            21.0            29.0   \n",
       "honor                1.0             1.0             2.0   \n",
       "\n",
       "doc      10_adams_john_quincy_1825      ...        49_reagan_1981  \\\n",
       "word                                    ...                         \n",
       "the                          304.0      ...                 123.0   \n",
       "america                        0.0      ...                   6.0   \n",
       "great                          9.0      ...                   4.0   \n",
       "honor                          1.0      ...                   0.0   \n",
       "\n",
       "doc      50_reagan_1985  51_bush_george_h_w_1989  52_clinton_1993  \\\n",
       "word                                                                \n",
       "the               132.0                    121.0             89.0   \n",
       "america             8.0                      7.0             19.0   \n",
       "great               5.0                     10.0              2.0   \n",
       "honor               1.0                      0.0              0.0   \n",
       "\n",
       "doc      53_clinton_1997  54_bush_george_w_2001  55_bush_george_w_2005  \\\n",
       "word                                                                     \n",
       "the                133.0                   53.0                  142.0   \n",
       "america             15.0                   11.0                   20.0   \n",
       "great                6.0                    3.0                    4.0   \n",
       "honor                0.0                    0.0                    3.0   \n",
       "\n",
       "doc      56_obama_2009  57_obama_2013  58_trump_2017  \n",
       "word                                                  \n",
       "the              132.0          104.0           71.0  \n",
       "america           10.0            8.0           20.0  \n",
       "great              1.0            3.0            6.0  \n",
       "honor              1.0            0.0            0.0  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a subset:\n",
    "\n",
    "word_doc.loc[[\"the\",\"america\",\"great\",\"honor\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>1</th>\n",
       "      <th>100</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>13</th>\n",
       "      <th>14th</th>\n",
       "      <th>...</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yourselves</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zachary</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_washington_1789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_washington_1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_adams_john_1797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_jefferson_1801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05_jefferson_1805</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word                000   03   04   05    1  100  120  125   13  14th  ...   \\\n",
       "doc                                                                    ...    \n",
       "01_washington_1789  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  ...    \n",
       "02_washington_1793  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    \n",
       "03_adams_john_1797  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    \n",
       "04_jefferson_1801   0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    \n",
       "05_jefferson_1805   0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    \n",
       "\n",
       "word                yours  yourself  yourselves  youth  youthful  zachary  \\\n",
       "doc                                                                         \n",
       "01_washington_1789    0.0       0.0         0.0    0.0       0.0      0.0   \n",
       "02_washington_1793    0.0       0.0         0.0    0.0       0.0      0.0   \n",
       "03_adams_john_1797    0.0       0.0         0.0    0.0       0.0      0.0   \n",
       "04_jefferson_1801     0.0       0.0         0.0    0.0       0.0      0.0   \n",
       "05_jefferson_1805     0.0       0.0         0.0    0.0       0.0      0.0   \n",
       "\n",
       "word                zeal  zealous  zealously  zone  \n",
       "doc                                                 \n",
       "01_washington_1789   0.0      0.0        0.0   0.0  \n",
       "02_washington_1793   0.0      0.0        0.0   0.0  \n",
       "03_adams_john_1797   1.0      0.0        0.0   0.0  \n",
       "04_jefferson_1801    1.0      0.0        0.0   0.0  \n",
       "05_jefferson_1805    3.0      0.0        0.0   0.0  \n",
       "\n",
       "[5 rows x 9281 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here words are rows and documents are columns, but if we change our minds and want the reverse, \n",
    "# transposition of a dataframe is easy:\n",
    "word_doc.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The marginal sums along each axis will give us total counts for each word:\n",
    "\n",
    "word_totals = word_doc.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and total words in each document:\n",
    "\n",
    "doc_totals = word_doc.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "000    13.0\n",
       "03     27.0\n",
       "04     26.0\n",
       "05      2.0\n",
       "1      22.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check these out (these are both of type Series rather than DataFrame):\n",
    "\n",
    "word_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc\n",
       "01_washington_1789    1436.0\n",
       "02_washington_1793     140.0\n",
       "03_adams_john_1797    2327.0\n",
       "04_jefferson_1801     1731.0\n",
       "05_jefferson_1805     2171.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To calculate word frequencies in each document, we need to divide each word's count\n",
    "# in its document by the total number of words in that document. We can do this easily \n",
    "# and logically in Pandas if we carefully specify the correct axis when dividing \n",
    "# our frame and our series. We'll call it \"tf\", but it's really a document-term frequency.\n",
    "\n",
    "tf = word_doc.div(doc_totals, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>doc</th>\n",
       "      <th>01_washington_1789</th>\n",
       "      <th>02_washington_1793</th>\n",
       "      <th>03_adams_john_1797</th>\n",
       "      <th>04_jefferson_1801</th>\n",
       "      <th>05_jefferson_1805</th>\n",
       "      <th>06_madison_1809</th>\n",
       "      <th>07_madison_1813</th>\n",
       "      <th>08_monroe_1817</th>\n",
       "      <th>09_monroe_1821</th>\n",
       "      <th>10_adams_john_quincy_1825</th>\n",
       "      <th>...</th>\n",
       "      <th>49_reagan_1981</th>\n",
       "      <th>50_reagan_1985</th>\n",
       "      <th>51_bush_george_h_w_1989</th>\n",
       "      <th>52_clinton_1993</th>\n",
       "      <th>53_clinton_1997</th>\n",
       "      <th>54_bush_george_w_2001</th>\n",
       "      <th>55_bush_george_w_2005</th>\n",
       "      <th>56_obama_2009</th>\n",
       "      <th>57_obama_2013</th>\n",
       "      <th>58_trump_2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>0.070047</td>\n",
       "      <td>0.075101</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.088136</td>\n",
       "      <td>0.082237</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.080268</td>\n",
       "      <td>0.104038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050020</td>\n",
       "      <td>0.050536</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>0.055108</td>\n",
       "      <td>0.061121</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.067943</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.048826</td>\n",
       "      <td>0.048168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.013569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upbraidings</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "doc          01_washington_1789  02_washington_1793  03_adams_john_1797  \\\n",
       "word                                                                      \n",
       "the                    0.080780            0.092857            0.070047   \n",
       "america                0.000000            0.007143            0.002149   \n",
       "great                  0.002089            0.000000            0.002149   \n",
       "upbraidings            0.000000            0.007143            0.000000   \n",
       "\n",
       "doc          04_jefferson_1801  05_jefferson_1805  06_madison_1809  \\\n",
       "word                                                                 \n",
       "the                   0.075101           0.065868         0.088136   \n",
       "america               0.000000           0.000000         0.000000   \n",
       "great                 0.000578           0.000461         0.000000   \n",
       "upbraidings           0.000000           0.000000         0.000000   \n",
       "\n",
       "doc          07_madison_1813  08_monroe_1817  09_monroe_1821  \\\n",
       "word                                                           \n",
       "the                 0.082237        0.081337        0.080268   \n",
       "america             0.000000        0.000000        0.000446   \n",
       "great               0.000000        0.006211        0.006466   \n",
       "upbraidings         0.000000        0.000000        0.000000   \n",
       "\n",
       "doc          10_adams_john_quincy_1825      ...        49_reagan_1981  \\\n",
       "word                                        ...                         \n",
       "the                           0.104038      ...              0.050020   \n",
       "america                       0.000000      ...              0.002440   \n",
       "great                         0.003080      ...              0.001627   \n",
       "upbraidings                   0.000000      ...              0.000000   \n",
       "\n",
       "doc          50_reagan_1985  51_bush_george_h_w_1989  52_clinton_1993  \\\n",
       "word                                                                    \n",
       "the                0.050536                 0.051533         0.055108   \n",
       "america            0.003063                 0.002981         0.011765   \n",
       "great              0.001914                 0.004259         0.001238   \n",
       "upbraidings        0.000000                 0.000000         0.000000   \n",
       "\n",
       "doc          53_clinton_1997  54_bush_george_w_2001  55_bush_george_w_2005  \\\n",
       "word                                                                         \n",
       "the                 0.061121               0.032960               0.067943   \n",
       "america             0.006893               0.006841               0.009569   \n",
       "great               0.002757               0.001866               0.001914   \n",
       "upbraidings         0.000000               0.000000               0.000000   \n",
       "\n",
       "doc          56_obama_2009  57_obama_2013  58_trump_2017  \n",
       "word                                                      \n",
       "the               0.054704       0.048826       0.048168  \n",
       "america           0.004144       0.003756       0.013569  \n",
       "great             0.000414       0.001408       0.004071  \n",
       "upbraidings       0.000000       0.000000       0.000000  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a subset, and compare with the numbers above:\n",
    "\n",
    "tf.loc[[\"the\",\"america\",\"great\",\"upbraidings\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In document '01_washington_1789' \n",
      "the word 'the' has frequency 0.080780, \n",
      "(116 occurrences / 1436 total words)\n"
     ]
    }
   ],
   "source": [
    "# Just an example to double-check that our numbers are plausible:\n",
    "trial_doc = \"01_washington_1789\"\n",
    "trial_word = \"the\"\n",
    "trial_count = int(word_doc.loc[trial_word,trial_doc])\n",
    "trial_total = int(doc_totals[trial_doc])\n",
    "trial_freq = tf.loc[trial_word,trial_doc]\n",
    "print(\"In document '{}' \\nthe word '{}' has frequency {:06f}, \\n({} occurrences / {} total words)\".format(\n",
    "    trial_doc, trial_word, trial_freq, trial_count, trial_total\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate TF-IDF, we multiply term frequencies by inverse document frequencies.\n",
    "We already have TF (term frequencies) in our doc_term_freq dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF will be a Series rather than a frame. For each word, we count how many documents it appears in, divide the total number of documents by that number, and take the natural logarithm of the result. \n",
    "\n",
    "If we have a word that appears in just 1 document of a total of 58 documents, our IDF will be: $$ln (\\frac{58}{1}) = 4.060443$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we calculate document counts for each word, using a convenient fact\n",
    "# about Python booleans as a shortcut. (docword>0) turns each cell into a Boolean value indicating\n",
    "# whether or not the document-word count is nonzero. We can sum over these Boolean values, and True instances\n",
    "# will count as 1, and False instances as 0.\n",
    "df = (word_doc>0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "zachary      1\n",
       "zeal         8\n",
       "zealous      5\n",
       "zealously    6\n",
       "zone         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it out (and let's try the other end of the series)\n",
    "# df records how many documents each term appears in:\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We know we have 58 inaugurals in our current data, \n",
    "# but rather than hard-code that, we can get the number of documents from one of our dataframes:\n",
    "numdocs = word_doc.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# At last we calculate idf:\n",
    "idf = np.log(numdocs/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word\n",
       "zachary      4.060443\n",
       "zeal         1.981001\n",
       "zealous      2.451005\n",
       "zealously    2.268684\n",
       "zone         4.060443\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it out; words that appear in fewer documents have higher idf scores:\n",
    "\n",
    "idf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# At last we can calculate tf-idf:\n",
    "tfidf = tf.mul(idf, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>doc</th>\n",
       "      <th>01_washington_1789</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>immutable</th>\n",
       "      <td>0.004690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impressions</th>\n",
       "      <td>0.004690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providential</th>\n",
       "      <td>0.004690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualifications</th>\n",
       "      <td>0.004125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>0.003926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peculiarly</th>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retreat</th>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pecuniary</th>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rendered</th>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliberations</th>\n",
       "      <td>0.003414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myself</th>\n",
       "      <td>0.003109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dare</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expedient</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ought</th>\n",
       "      <td>0.002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supplication</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliberating</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improper</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discernment</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auspiciously</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fifth</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aver</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inapplicable</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interruptions</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>designates</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notification</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palliated</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awaken</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpracticed</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indispensably</th>\n",
       "      <td>0.002828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existed</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existence</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>existing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exonerated</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expanded</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exerted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expanding</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expands</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expansion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expect</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectation</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectations</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exile</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exigency</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exigencies</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhortations</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhortation</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhilarated</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhibitions</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhibiting</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhibited</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhibit</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhaustless</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhaustive</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhausting</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhausted</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exhaust</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exertions</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exertion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9281 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "doc             01_washington_1789\n",
       "word                              \n",
       "immutable                 0.004690\n",
       "impressions               0.004690\n",
       "providential              0.004690\n",
       "qualifications            0.004125\n",
       "your                      0.003926\n",
       "peculiarly                0.003724\n",
       "retreat                   0.003414\n",
       "pecuniary                 0.003414\n",
       "article                   0.003414\n",
       "rendered                  0.003414\n",
       "deliberations             0.003414\n",
       "myself                    0.003109\n",
       "dare                      0.002945\n",
       "expedient                 0.002945\n",
       "ought                     0.002830\n",
       "supplication              0.002828\n",
       "deliberating              0.002828\n",
       "improper                  0.002828\n",
       "discernment               0.002828\n",
       "auspiciously              0.002828\n",
       "fifth                     0.002828\n",
       "aver                      0.002828\n",
       "inapplicable              0.002828\n",
       "interruptions             0.002828\n",
       "designates                0.002828\n",
       "notification              0.002828\n",
       "palliated                 0.002828\n",
       "awaken                    0.002828\n",
       "unpracticed               0.002828\n",
       "indispensably             0.002828\n",
       "...                            ...\n",
       "existed                   0.000000\n",
       "existence                 0.000000\n",
       "existing                  0.000000\n",
       "exonerated                0.000000\n",
       "expanded                  0.000000\n",
       "exerted                   0.000000\n",
       "expanding                 0.000000\n",
       "expands                   0.000000\n",
       "expansion                 0.000000\n",
       "expect                    0.000000\n",
       "expectation               0.000000\n",
       "expectations              0.000000\n",
       "exile                     0.000000\n",
       "exigency                  0.000000\n",
       "exigencies                0.000000\n",
       "exhortations              0.000000\n",
       "exhortation               0.000000\n",
       "exhilarated               0.000000\n",
       "exhibitions               0.000000\n",
       "exhibiting                0.000000\n",
       "exhibited                 0.000000\n",
       "exhibit                   0.000000\n",
       "exhaustless               0.000000\n",
       "exhaustive                0.000000\n",
       "exhausting                0.000000\n",
       "exhausted                 0.000000\n",
       "exhaust                   0.000000\n",
       "exertions                 0.000000\n",
       "exertion                  0.000000\n",
       "zone                      0.000000\n",
       "\n",
       "[9281 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a sample; for one document, we sort the tf-idf scores in descending order to see\n",
    "# the characteristic words\n",
    "trialdoc = '01_washington_1789'\n",
    "tfidf.loc[:,[trialdoc]].sort_values(by=trialdoc, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docnames = doc_totals.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       01_washington_1789  immutable impressions providential qualifications your peculiarly retreat pecuniary\n",
      "       02_washington_1793  arrive 1793 upbraidings willingly violated incurring injunctions previous\n",
      "       03_adams_john_1797  pleasing houses legislatures virtuous amiable habitual legislature benevolence\n",
      "        04_jefferson_1801  thousandth retire moments intolerance trusted principle him honest\n",
      "        05_jefferson_1805  whatsoever false covered enlighten falsehood defamation licentiousness comforts\n",
      "          06_madison_1809  improvements belligerent rendered distressing inadequacy exempted unwarrantable partialities\n",
      "          07_madison_1813  british massacre prisoners savage cruel captives until enemy\n",
      "           08_monroe_1817  trials naval put invasion dangers situated duly persevere\n",
      "           09_monroe_1821  colonies occurrences preceding spain concluded fortifications 000 coast\n",
      "10_adams_john_quincy_1825  union dissensions instituted performance candid whatsoever picture contention\n",
      "          11_jackson_1829  diffidence defending generally worth accountability cover introduction consist\n",
      "          12_jackson_1833  inculcate proportion constitutionally union preservation intentions exercise impressed\n",
      "        13_van_buren_1837  supposed institutions occasionally actual adherence designed evidently foreboding\n",
      "         14_harrison_1841  roman executive grant conceive operations aristocracy remark constitution\n",
      "             15_polk_1845  texas union her revenue compromises majorities levying reunion\n",
      "           16_taylor_1849  purity vested affections conflicting surrounded onerous defer promulgation\n",
      "           17_pierce_1853  hardly your consult preferment apparent regarded counsels readily\n",
      "         18_buchanan_1857  whilst territory agitation question slavery kansas squandering speedily\n",
      "          19_lincoln_1861  clause secede minority case lawfully surrendered union plainly\n",
      "          20_lincoln_1865  woe offenses wills offense answered slaves altogether address\n",
      "            21_grant_1869  dollar paying specie deal advisable five payments debt\n",
      "            22_grant_1873  santo domingo transit proposition steam extermination telegraph him\n",
      "            23_hayes_1877  behalf dispute nomination complications reform races parties repeat\n",
      "         24_garfield_1881  negro notes incumbents suffrage ballot voters concerning jurisdiction\n",
      "        25_cleveland_1885  yours partisan extravagance commended strife appreciation application claims\n",
      "         26_harrison_1889  ballot methods european friendly laws cotton electors ships\n",
      "        27_cleveland_1893  frugality aggregations governmental activity related taxing kindred combinations\n",
      "         28_mckinley_1897  loans revenue revision congress legislation session convene merchant\n",
      "         29_mckinley_1901  cuba islands inhabitants instructions philippine preparation executive permanence\n",
      "30_roosevelt_theodore_1905  regards aright tasks problems faced heritage 1905 hardier\n",
      "             31_taft_1909  interstate negro business tariff canal type south employees\n",
      "           32_wilson_1913  familiar stirred studied safeguarding inconceivable sweep intimate interpret\n",
      "           33_wilson_1917  wished counsel singular despite currents politics drawn processes\n",
      "          34_harding_1921  relationship civilization amid normal understanding unshaken activities america\n",
      "         35_coolidge_1925  represents stands array tax property unless ought save\n",
      "           36_hoover_1929  enforcement 18th ideals criminals liquor rightly domination federal\n",
      "37_roosevelt_franklin_1933  helped leadership stricken emergency discipline respects languishes critical\n",
      "38_roosevelt_franklin_1937  paint democracy timidity aught opportunism epidemics ruthless millions\n",
      "39_roosevelt_franklin_1941  speaks democracy 1941 disruption stock measured something 1789\n",
      "40_roosevelt_franklin_1945  learned 1945 trend test mistakes upward gain anguished\n",
      "           41_truman_1949  program communism philosophy major recovery peoples aided technical\n",
      "       42_eisenhower_1953  productivity peoples soldier precepts stamina korea mountains spiritual\n",
      "       43_eisenhower_1957  strives peoples skills divided mr help seek honorably\n",
      "          44_kennedy_1961  sides pledge let explore both dare final begin\n",
      "          45_johnson_1965  covenant mastery change mars shoulder rocket harvest trying\n",
      "            46_nixon_1969  voices rhetoric moon brothers third adventure catch riders\n",
      "            47_nixon_1973  role america policies abroad let ashamed gladly era\n",
      "           48_carter_1977  dream micah thee mistakes enhance bible together basic\n",
      "           49_reagan_1981  re m heroes weapon productivity ve americans monument\n",
      "           50_reagan_1985  nuclear ve weapons t song senator budget reduce\n",
      "  51_bush_george_h_w_1989  t breeze don door blowing word crucial engagement\n",
      "          52_clinton_1993  america americans season renewal idea today sake change\n",
      "          53_clinton_1997  century promise 20th 21st america enough yes 19th\n",
      "    54_bush_george_w_2001  story civility affirm directs whirlwind stakes rides compassion\n",
      "    55_bush_george_w_2005  freedom america tyranny americans resentment excuse your fire\n",
      "            56_obama_2009  icy jobs storms waters winter america generation journey\n",
      "            57_obama_2013  journey creed she train evident generation requires complete\n",
      "            58_trump_2017  america dreams jobs everyone obama trillions transferring 2017\n"
     ]
    }
   ],
   "source": [
    "for docname in doc_totals.index:\n",
    "    topwords = list(tfidf.loc[:,[docname]].sort_values(by=docname, ascending=False)[docname].index[:8])\n",
    "    print(\"{:>25s} \".format(docname),\" \".join(topwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
